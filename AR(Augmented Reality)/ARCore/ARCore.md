# ARCore

## 概览

+ Google的增强现实体验构建平台
+ 三大功能要点
  + 运动跟踪：手机可以理解和跟踪它相对于现实世界的位置
  + 环境理解：手机可以检测各类表面的大小和位置
  + 光估测：手机可以估测环境当前的光照条件
+ 工作原理
  + 在移动设备移动时跟踪它的位置和构建自己对现实世界的理解
  + ARCore的运动跟踪技术使用手机摄像头标识兴趣点（特征点），并跟踪这些点随着时间变化的移动。将这些点的移动与手机惯性传感器的读数组合，ARCore可以在手机移动时确定它的位置和屏幕方向。
  + ARCore还会检测平坦的表面，并估测周围区域的平均光照强度。这些功能共同让ARCore可以构建自己对周围世界的理解。

## 基本概念

+ 运动跟踪
  + ARCore通过一个名为并行测距与映射（COM）的过程来理解手机相对于周围世界的位置。
  + 捕捉摄像头图像中的视觉差异特征（特征点），计算位置变化。
  + 将视觉信息和设备IMU的惯性测量结果结合，可以用于估测摄像头随着时间推移相对于周围世界的姿态（方向和位置）。
  + 通过将渲染3D内容的虚拟摄像头姿态和ARCore提供的设备摄像头的姿态对齐，开发者可以从正确的透视角度渲染虚拟内容。
+ 环境理解
  + ARCore可以查找看起来位于常见水平或垂直表面上成簇特征点，让这些表面可以由您的应用用作平面。
  + ARCore也可以确定每个平面的边界，该信息可用于将虚拟物体置于平坦的表面上
+ 光估测
  + ARCore可以检测其环境光线的相关信息，提供给定摄像头图像的平均光强度和色彩校正。
  + 让你能够使用与环境相同的光照来照亮虚拟物体，提升真实感。
+ 用户交互
  + ARCore利用命中测试来获取对应于手机屏幕的(x,y)坐标，并将一条射线投影到摄像头的视野中，返回着跳射线贯穿的任何平面或特征点以及交叉位置在现实世界空间的姿态。
+ 定向点
  + 借助定向点，执行会返回特征点的命中测试时，ARCore将查看附近的特征点并使用这些点估算表面在给定特征点处的角度，返回一个将该角度考虑在内的姿态。
+ 锚和可跟踪对象
  + 定义锚点确保ARCore可以跟踪物体随时间推移的位置。
  + 平面和特征点称为可跟踪对象，ARCore随着时间推移跟踪这些物体。将物体锚定到特定地可跟踪对象，确保虚拟物体与可跟踪对象之间的关系即使在设备移动时也能保持稳定。
+ 增强图像
  + 使用增强图形构建能够响应特定2D图像的AR应用。
+ 共享
  + 使用云锚点，一台设备可以将锚点和附近的特征点发送到云端进行托管。可用于同一环境中的设备用户共享，这使应用可以渲染连接到这些锚点的相同3D对象，拥有同步相同的AR体验。

## 开发者指南 -- 使用锚点